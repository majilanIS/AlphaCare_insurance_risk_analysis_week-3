{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dc5fb4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: environment and imports\n",
    "# If you need to install packages, uncomment and run the pip lines once.\n",
    "# !pip install pandas numpy scipy statsmodels matplotlib seaborn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "from statsmodels.stats.proportion import proportions_ztest\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "alpha = 0.05   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2ba63234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: ../data/MachineLearningRating_v3.txt\n",
      "Rows, cols: (1000098, 52)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UnderwrittenCoverID</th>\n",
       "      <th>PolicyID</th>\n",
       "      <th>TransactionMonth</th>\n",
       "      <th>IsVATRegistered</th>\n",
       "      <th>Citizenship</th>\n",
       "      <th>LegalType</th>\n",
       "      <th>Title</th>\n",
       "      <th>Language</th>\n",
       "      <th>Bank</th>\n",
       "      <th>AccountType</th>\n",
       "      <th>...</th>\n",
       "      <th>ExcessSelected</th>\n",
       "      <th>CoverCategory</th>\n",
       "      <th>CoverType</th>\n",
       "      <th>CoverGroup</th>\n",
       "      <th>Section</th>\n",
       "      <th>Product</th>\n",
       "      <th>StatutoryClass</th>\n",
       "      <th>StatutoryRiskType</th>\n",
       "      <th>TotalPremium</th>\n",
       "      <th>TotalClaims</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>145249</td>\n",
       "      <td>12827</td>\n",
       "      <td>2015-03-01 00:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td>Close Corporation</td>\n",
       "      <td>Mr</td>\n",
       "      <td>English</td>\n",
       "      <td>First National Bank</td>\n",
       "      <td>Current account</td>\n",
       "      <td>...</td>\n",
       "      <td>Mobility - Windscreen</td>\n",
       "      <td>Windscreen</td>\n",
       "      <td>Windscreen</td>\n",
       "      <td>Comprehensive - Taxi</td>\n",
       "      <td>Motor Comprehensive</td>\n",
       "      <td>Mobility Metered Taxis: Monthly</td>\n",
       "      <td>Commercial</td>\n",
       "      <td>IFRS Constant</td>\n",
       "      <td>21.929825</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>145249</td>\n",
       "      <td>12827</td>\n",
       "      <td>2015-05-01 00:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td>Close Corporation</td>\n",
       "      <td>Mr</td>\n",
       "      <td>English</td>\n",
       "      <td>First National Bank</td>\n",
       "      <td>Current account</td>\n",
       "      <td>...</td>\n",
       "      <td>Mobility - Windscreen</td>\n",
       "      <td>Windscreen</td>\n",
       "      <td>Windscreen</td>\n",
       "      <td>Comprehensive - Taxi</td>\n",
       "      <td>Motor Comprehensive</td>\n",
       "      <td>Mobility Metered Taxis: Monthly</td>\n",
       "      <td>Commercial</td>\n",
       "      <td>IFRS Constant</td>\n",
       "      <td>21.929825</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>145249</td>\n",
       "      <td>12827</td>\n",
       "      <td>2015-07-01 00:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td>Close Corporation</td>\n",
       "      <td>Mr</td>\n",
       "      <td>English</td>\n",
       "      <td>First National Bank</td>\n",
       "      <td>Current account</td>\n",
       "      <td>...</td>\n",
       "      <td>Mobility - Windscreen</td>\n",
       "      <td>Windscreen</td>\n",
       "      <td>Windscreen</td>\n",
       "      <td>Comprehensive - Taxi</td>\n",
       "      <td>Motor Comprehensive</td>\n",
       "      <td>Mobility Metered Taxis: Monthly</td>\n",
       "      <td>Commercial</td>\n",
       "      <td>IFRS Constant</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>145255</td>\n",
       "      <td>12827</td>\n",
       "      <td>2015-05-01 00:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td>Close Corporation</td>\n",
       "      <td>Mr</td>\n",
       "      <td>English</td>\n",
       "      <td>First National Bank</td>\n",
       "      <td>Current account</td>\n",
       "      <td>...</td>\n",
       "      <td>Mobility - Metered Taxis - R2000</td>\n",
       "      <td>Own damage</td>\n",
       "      <td>Own Damage</td>\n",
       "      <td>Comprehensive - Taxi</td>\n",
       "      <td>Motor Comprehensive</td>\n",
       "      <td>Mobility Metered Taxis: Monthly</td>\n",
       "      <td>Commercial</td>\n",
       "      <td>IFRS Constant</td>\n",
       "      <td>512.848070</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>145255</td>\n",
       "      <td>12827</td>\n",
       "      <td>2015-07-01 00:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td>Close Corporation</td>\n",
       "      <td>Mr</td>\n",
       "      <td>English</td>\n",
       "      <td>First National Bank</td>\n",
       "      <td>Current account</td>\n",
       "      <td>...</td>\n",
       "      <td>Mobility - Metered Taxis - R2000</td>\n",
       "      <td>Own damage</td>\n",
       "      <td>Own Damage</td>\n",
       "      <td>Comprehensive - Taxi</td>\n",
       "      <td>Motor Comprehensive</td>\n",
       "      <td>Mobility Metered Taxis: Monthly</td>\n",
       "      <td>Commercial</td>\n",
       "      <td>IFRS Constant</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   UnderwrittenCoverID  PolicyID     TransactionMonth  IsVATRegistered  \\\n",
       "0               145249     12827  2015-03-01 00:00:00             True   \n",
       "1               145249     12827  2015-05-01 00:00:00             True   \n",
       "2               145249     12827  2015-07-01 00:00:00             True   \n",
       "3               145255     12827  2015-05-01 00:00:00             True   \n",
       "4               145255     12827  2015-07-01 00:00:00             True   \n",
       "\n",
       "  Citizenship          LegalType Title Language                 Bank  \\\n",
       "0              Close Corporation    Mr  English  First National Bank   \n",
       "1              Close Corporation    Mr  English  First National Bank   \n",
       "2              Close Corporation    Mr  English  First National Bank   \n",
       "3              Close Corporation    Mr  English  First National Bank   \n",
       "4              Close Corporation    Mr  English  First National Bank   \n",
       "\n",
       "       AccountType  ...                    ExcessSelected CoverCategory  \\\n",
       "0  Current account  ...             Mobility - Windscreen    Windscreen   \n",
       "1  Current account  ...             Mobility - Windscreen    Windscreen   \n",
       "2  Current account  ...             Mobility - Windscreen    Windscreen   \n",
       "3  Current account  ...  Mobility - Metered Taxis - R2000    Own damage   \n",
       "4  Current account  ...  Mobility - Metered Taxis - R2000    Own damage   \n",
       "\n",
       "    CoverType            CoverGroup              Section  \\\n",
       "0  Windscreen  Comprehensive - Taxi  Motor Comprehensive   \n",
       "1  Windscreen  Comprehensive - Taxi  Motor Comprehensive   \n",
       "2  Windscreen  Comprehensive - Taxi  Motor Comprehensive   \n",
       "3  Own Damage  Comprehensive - Taxi  Motor Comprehensive   \n",
       "4  Own Damage  Comprehensive - Taxi  Motor Comprehensive   \n",
       "\n",
       "                           Product StatutoryClass StatutoryRiskType  \\\n",
       "0  Mobility Metered Taxis: Monthly     Commercial     IFRS Constant   \n",
       "1  Mobility Metered Taxis: Monthly     Commercial     IFRS Constant   \n",
       "2  Mobility Metered Taxis: Monthly     Commercial     IFRS Constant   \n",
       "3  Mobility Metered Taxis: Monthly     Commercial     IFRS Constant   \n",
       "4  Mobility Metered Taxis: Monthly     Commercial     IFRS Constant   \n",
       "\n",
       "   TotalPremium TotalClaims  \n",
       "0     21.929825         0.0  \n",
       "1     21.929825         0.0  \n",
       "2      0.000000         0.0  \n",
       "3    512.848070         0.0  \n",
       "4      0.000000         0.0  \n",
       "\n",
       "[5 rows x 52 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 2: load the dataset (adjust path if needed)\n",
    "data_path = \"../data/MachineLearningRating_v3.txt\"\n",
    "df = pd.read_csv(data_path, sep=\"|\", low_memory=False)\n",
    "\n",
    "print(\"Loaded:\", data_path)\n",
    "print(\"Rows, cols:\", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "77e94025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest zip groups: PostalCode\n",
      "7340    1\n",
      "3655    1\n",
      "322     1\n",
      "7760    1\n",
      "7560    1\n",
      "7350    1\n",
      "2210    1\n",
      "7463    1\n",
      "7789    1\n",
      "8584    1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "by_zip = df.groupby('PostalCode').size().sort_values(ascending=False)\n",
    "print(\"Smallest zip groups:\", by_zip.tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1cec828f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KPIs created. Summary:\n",
      "Total policies: 1000098\n",
      "Policies with claim: 2788\n",
      "Columns include: ['claim_flag', 'claim_severity', 'margin']\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: KPI derivation\n",
    "# Ensure numeric columns\n",
    "for c in ['TotalPremium','TotalClaims']:\n",
    "    if c in df.columns:\n",
    "        df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "\n",
    "df['claim_flag'] = (df['TotalClaims'] > 0).astype(int)               \n",
    "df['claim_severity'] = df['TotalClaims'].where(df['claim_flag']==1)\n",
    "df['margin'] = df['TotalPremium'] - df['TotalClaims']\n",
    "\n",
    "print(\"KPIs created. Summary:\")\n",
    "print(\"Total policies:\", len(df))\n",
    "print(\"Policies with claim:\", df['claim_flag'].sum())\n",
    "print(\"Columns include:\", [c for c in ['claim_flag','claim_severity','margin'] if c in df.columns])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "43fd09c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Provinces:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Province\n",
       "Gauteng          393865\n",
       "Western Cape     170796\n",
       "KwaZulu-Natal    169781\n",
       "North West       143287\n",
       "Mpumalanga        52718\n",
       "Eastern Cape      30336\n",
       "Limpopo           24836\n",
       "Free State         8099\n",
       "Northern Cape      6380\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top PostalCodes:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PostalCode\n",
       "2000    133498\n",
       "122      49171\n",
       "7784     28585\n",
       "299      25546\n",
       "7405     18518\n",
       "458      13775\n",
       "8000     11794\n",
       "2196     11048\n",
       "470      10226\n",
       "7100     10161\n",
       "1724     10107\n",
       "4360      9730\n",
       "302       9531\n",
       "152       9423\n",
       "7750      9408\n",
       "1863      8655\n",
       "1022      8476\n",
       "4068      8234\n",
       "400       6692\n",
       "4001      6647\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gender values:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Gender\n",
       "Not specified    940990\n",
       "Male              42817\n",
       "Female             6755\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cell 4: clean Province / PostalCode / Gender columns and show counts\n",
    "# Normalize string columns safely\n",
    "for col in ['Province','PostalCode','Gender','PostalCode']:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].astype(str).str.strip().replace({'nan': np.nan})\n",
    "\n",
    "print(\"Top Provinces:\")\n",
    "if 'Province' in df.columns:\n",
    "    display(df['Province'].value_counts().head(20))\n",
    "else:\n",
    "    print(\"No Province column found.\")\n",
    "\n",
    "print(\"\\nTop PostalCodes:\")\n",
    "if 'PostalCode' in df.columns:\n",
    "    display(df['PostalCode'].value_counts().head(20))\n",
    "else:\n",
    "    print(\"No PostalCode column found.\")\n",
    "\n",
    "print(\"\\nGender values:\")\n",
    "if 'Gender' in df.columns:\n",
    "    display(df['Gender'].value_counts())\n",
    "else:\n",
    "    print(\"No Gender column found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7348de12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: helper functions\n",
    "def print_decision(p_value, alpha=alpha):\n",
    "    decision = \"REJECT null hypothesis\" if p_value < alpha else \"FAIL TO REJECT null hypothesis\"\n",
    "    print(f\"p-value = {p_value:.6f} | alpha = {alpha} -> {decision}\")\n",
    "    return decision\n",
    "\n",
    "def normality_test(series):\n",
    "    s = series.dropna()\n",
    "    if len(s) < 3:\n",
    "        return False, np.nan\n",
    "    if len(s) <= 5000:\n",
    "        stat, p = stats.shapiro(s)\n",
    "        return p >= alpha, p\n",
    "    else:\n",
    "        stat, p = stats.kstest((s - s.mean())/s.std(ddof=0), 'norm')\n",
    "        return p >= alpha, p\n",
    "\n",
    "def equal_variance_test(*groups):\n",
    "    groups = [g.dropna() for g in groups]\n",
    "    if any(len(g)<2 for g in groups):\n",
    "        return False, np.nan\n",
    "    stat, p = stats.levene(*groups)\n",
    "    return p >= alpha, p\n",
    "\n",
    "def safe_independent_ttest(a,b):\n",
    "    eq_var, p_levene = equal_variance_test(a,b)\n",
    "    tstat, p = stats.ttest_ind(a.dropna(), b.dropna(), equal_var=eq_var)\n",
    "    return tstat, p, eq_var, p_levene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d0dca45c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== H0: No risk differences across Provinces ===\n",
      "\n",
      "Contingency table (Province x claim_flag) sample:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>claim_flag</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Province</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Eastern Cape</th>\n",
       "      <td>30286</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Free State</th>\n",
       "      <td>8088</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gauteng</th>\n",
       "      <td>392543</td>\n",
       "      <td>1322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KwaZulu-Natal</th>\n",
       "      <td>169298</td>\n",
       "      <td>483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Limpopo</th>\n",
       "      <td>24769</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "claim_flag          0     1\n",
       "Province                   \n",
       "Eastern Cape    30286    50\n",
       "Free State       8088    11\n",
       "Gauteng        392543  1322\n",
       "KwaZulu-Natal  169298   483\n",
       "Limpopo         24769    67"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Claim Frequency across Provinces (Chi-squared):\n",
      "p-value = 0.000000 | alpha = 0.05 -> REJECT null hypothesis\n",
      "\n",
      "Province groups used for severity test (n>=5): 9\n",
      "Kruskal-Wallis (claim severity):\n",
      "p-value = 0.000000 | alpha = 0.05 -> REJECT null hypothesis\n",
      "\n",
      "Province groups used for margin test (n>=10): 9\n",
      "Kruskal-Wallis (margin):\n",
      "p-value = 0.000000 | alpha = 0.05 -> REJECT null hypothesis\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Province-level hypothesis testing\n",
    "print(\"=== H0: No risk differences across Provinces ===\\n\")\n",
    "if 'Province' not in df.columns:\n",
    "    print(\"Province column not present. Aborting province tests.\")\n",
    "else:\n",
    "    # 1) Claim Frequency: chi-square test\n",
    "    contingency = pd.crosstab(df['Province'], df['claim_flag'])\n",
    "    print(\"Contingency table (Province x claim_flag) sample:\")\n",
    "    display(contingency.head())\n",
    "    chi2, p_chi, dof, exp = stats.chi2_contingency(contingency)\n",
    "    print(\"\\nClaim Frequency across Provinces (Chi-squared):\")\n",
    "    print_decision(p_chi)\n",
    "\n",
    "    # 2) Claim Severity across provinces - collect groups with >=5 severity observations\n",
    "    sev_groups = []\n",
    "    sev_labels = []\n",
    "    for prov, g in df.groupby('Province'):\n",
    "        s = g['claim_severity'].dropna()\n",
    "        if len(s) >= 5:\n",
    "            sev_groups.append(s)\n",
    "            sev_labels.append(prov)\n",
    "    print(f\"\\nProvince groups used for severity test (n>=5): {len(sev_groups)}\")\n",
    "    if len(sev_groups) >= 2:\n",
    "        normals = [normality_test(g)[0] for g in sev_groups]\n",
    "        if all(normals):\n",
    "            fstat, p_anova = stats.f_oneway(*sev_groups)\n",
    "            print(\"ANOVA (claim severity across provinces):\")\n",
    "            print_decision(p_anova)\n",
    "            if p_anova < alpha:\n",
    "                # Tukey post-hoc\n",
    "                subset = df.dropna(subset=['claim_severity','Province'])[['claim_severity','Province']]\n",
    "                print(\"\\nTukey HSD (pairwise differences):\")\n",
    "                print(pairwise_tukeyhsd(subset['claim_severity'], subset['Province']))\n",
    "        else:\n",
    "            hstat, p_kw = stats.kruskal(*sev_groups)\n",
    "            print(\"Kruskal-Wallis (claim severity):\")\n",
    "            print_decision(p_kw)\n",
    "    else:\n",
    "        print(\"Not enough province groups with claim severity data to test severity differences.\")\n",
    "\n",
    "    # 3) Margin across provinces - use groups with at least 10 policies\n",
    "    margin_groups = []\n",
    "    margin_labels = []\n",
    "    for prov, g in df.groupby('Province'):\n",
    "        s = g['margin'].dropna()\n",
    "        if len(s) >= 10:\n",
    "            margin_groups.append(s)\n",
    "            margin_labels.append(prov)\n",
    "    print(f\"\\nProvince groups used for margin test (n>=10): {len(margin_groups)}\")\n",
    "    if len(margin_groups) >= 2:\n",
    "        normals_m = [normality_test(g)[0] for g in margin_groups]\n",
    "        if all(normals_m):\n",
    "            fstat_m, p_anova_m = stats.f_oneway(*margin_groups)\n",
    "            print(\"ANOVA (margin across provinces):\")\n",
    "            print_decision(p_anova_m)\n",
    "            if p_anova_m < alpha:\n",
    "                subset_m = df.dropna(subset=['margin','Province'])[['margin','Province']]\n",
    "                print(\"\\nTukey HSD (margin):\")\n",
    "                print(pairwise_tukeyhsd(subset_m['margin'], subset_m['Province']))\n",
    "        else:\n",
    "            hstat_m, p_kw_m = stats.kruskal(*margin_groups)\n",
    "            print(\"Kruskal-Wallis (margin):\")\n",
    "            print_decision(p_kw_m)\n",
    "    else:\n",
    "        print(\"Not enough province groups with margin data to test margin differences.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9ff4e3aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== H0: No significant margin differences across Postal Codes (multi-group) ===\n",
      "\n",
      "Postal codes with >= 20 records: 843\n",
      "Kruskal-Wallis (margin across postal codes):\n",
      "p-value = 0.000000 | alpha = 0.05 -> REJECT null hypothesis\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Margin differences across many postal codes (ANOVA / Kruskal) - use postal codes with n>=min_count\n",
    "print(\"=== H0: No significant margin differences across Postal Codes (multi-group) ===\\n\")\n",
    "if 'PostalCode' not in df.columns:\n",
    "    print(\"PostalCode column missing.\")\n",
    "else:\n",
    "    min_count = 20\n",
    "    postal_groups = []\n",
    "    labels = []\n",
    "    for pc, g in df.groupby('PostalCode'):\n",
    "        if len(g) >= min_count:\n",
    "            postal_groups.append(g['margin'].dropna())\n",
    "            labels.append(pc)\n",
    "    print(f\"Postal codes with >= {min_count} records: {len(labels)}\")\n",
    "    if len(postal_groups) < 2:\n",
    "        print(\"Not enough postal-code groups to run multi-group test.\")\n",
    "    else:\n",
    "        normals = [normality_test(g)[0] for g in postal_groups]\n",
    "        if all(normals):\n",
    "            fstat, p_anova = stats.f_oneway(*postal_groups)\n",
    "            print(\"ANOVA (margin across postal codes):\")\n",
    "            print_decision(p_anova)\n",
    "            if p_anova < alpha:\n",
    "                subset = df[df['PostalCode'].isin(labels)][['margin','PostalCode']].dropna()\n",
    "                print(\"\\nTukey HSD (pairwise postal code differences):\")\n",
    "                print(pairwise_tukeyhsd(subset['margin'], subset['PostalCode']))\n",
    "        else:\n",
    "            hstat, p_kw = stats.kruskal(*postal_groups)\n",
    "            print(\"Kruskal-Wallis (margin across postal codes):\")\n",
    "            print_decision(p_kw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cba0fa56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== H0: No significant risk difference between Women and Men ===\n",
      "\n",
      "Gender counts:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "gender_group\n",
       "other     950526\n",
       "male       42817\n",
       "female      6755\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Claim frequency: female 14/6755 vs male 94/42817\n",
      "Proportions z-test (claim frequency by gender):\n",
      "p-value = 0.840494 | alpha = 0.05 -> FAIL TO REJECT null hypothesis\n",
      "\n",
      "Severity normality: female -> True (p=0.11092318701431175), male -> False (p=1.2189369420515468e-15)\n",
      "Mann-Whitney for severity by gender:\n",
      "p-value = 0.223513 | alpha = 0.05 -> FAIL TO REJECT null hypothesis\n",
      "\n",
      "Mann-Whitney for margin by gender:\n",
      "p-value = 0.000000 | alpha = 0.05 -> REJECT null hypothesis\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: Gender tests (claim frequency, severity, margin)\n",
    "print(\"=== H0: No significant risk difference between Women and Men ===\\n\")\n",
    "if 'Gender' not in df.columns:\n",
    "    print(\"Gender column not present. Aborting gender tests.\")\n",
    "else:\n",
    "    # Normalize gender into male/female/other\n",
    "    gcol = df['Gender'].astype(str).str.strip().str.lower()\n",
    "    female_vals = set(['f','female','woman','women'])\n",
    "    male_vals = set(['m','male','man','men'])\n",
    "    df['gender_group'] = gcol.apply(lambda x: 'female' if x in female_vals else ('male' if x in male_vals else 'other'))\n",
    "\n",
    "    print(\"Gender counts:\")\n",
    "    display(df['gender_group'].value_counts())\n",
    "\n",
    "    # Keep only male/female\n",
    "    gender_df = df[df['gender_group'].isin(['female','male'])]\n",
    "    female = gender_df[gender_df['gender_group']=='female']\n",
    "    male = gender_df[gender_df['gender_group']=='male']\n",
    "\n",
    "    # Claim frequency z-test\n",
    "    cf_f, n_f = female['claim_flag'].sum(), len(female)\n",
    "    cf_m, n_m = male['claim_flag'].sum(), len(male)\n",
    "    print(f\"\\nClaim frequency: female {cf_f}/{n_f} vs male {cf_m}/{n_m}\")\n",
    "    if n_f==0 or n_m==0:\n",
    "        print(\"Insufficient gender counts for z-test.\")\n",
    "    else:\n",
    "        stat_g, p_g = proportions_ztest([cf_f, cf_m], [n_f, n_m])\n",
    "        print(\"Proportions z-test (claim frequency by gender):\")\n",
    "        print_decision(p_g)\n",
    "\n",
    "    # Severity comparison\n",
    "    sev_f = female['claim_severity'].dropna()\n",
    "    sev_m = male['claim_severity'].dropna()\n",
    "    if len(sev_f) < 3 or len(sev_m) < 3:\n",
    "        print(\"\\nToo few severity samples in one of the gender groups for reliable test.\")\n",
    "    else:\n",
    "        nf, nm = len(sev_f), len(sev_m)\n",
    "        nf_norm, pnf = normality_test(sev_f)\n",
    "        nm_norm, pnm = normality_test(sev_m)\n",
    "        print(f\"\\nSeverity normality: female -> {nf_norm} (p={pnf}), male -> {nm_norm} (p={pnm})\")\n",
    "        if nf_norm and nm_norm:\n",
    "            t_s, p_s, eqv_s, lv_s = safe_independent_ttest(sev_f, sev_m)\n",
    "            print(\"T-test for severity by gender:\")\n",
    "            print(f\"Levene p={lv_s:.6f}, equal_var={eqv_s}\")\n",
    "            print_decision(p_s)\n",
    "        else:\n",
    "            u_s, p_mw_s = stats.mannwhitneyu(sev_f, sev_m, alternative='two-sided')\n",
    "            print(\"Mann-Whitney for severity by gender:\")\n",
    "            print_decision(p_mw_s)\n",
    "\n",
    "    # Margin comparison\n",
    "    m_f = female['margin'].dropna()\n",
    "    m_m = male['margin'].dropna()\n",
    "    if len(m_f) < 5 or len(m_m) < 5:\n",
    "        print(\"\\nToo few margin records in one of the gender groups for robust test.\")\n",
    "    else:\n",
    "        nmf, pmf = normality_test(m_f)\n",
    "        nmm, pmm = normality_test(m_m)\n",
    "        if nmf and nmm:\n",
    "            t_mg, p_mg, eqv_mg, lv_mg = safe_independent_ttest(m_f, m_m)\n",
    "            print(\"\\nT-test for margin by gender:\")\n",
    "            print(f\"Levene p={lv_mg:.6f}, equal_var={eqv_mg}\")\n",
    "            print_decision(p_mg)\n",
    "        else:\n",
    "            u_mg, p_mw_mg = stats.mannwhitneyu(m_f, m_m, alternative='two-sided')\n",
    "            print(\"\\nMann-Whitney for margin by gender:\")\n",
    "            print_decision(p_mw_mg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "844973c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bonferroni adjusted alpha for 6 tests: 0.008333\n",
      "If you want FDR (Benjamini-Hochberg), use statsmodels.sandbox or custom code.\n"
     ]
    }
   ],
   "source": [
    "# Cell 10: If you ran many tests and want to control family-wise error, use Bonferroni\n",
    "# Example: if you run k independent hypothesis tests, adjusted_alpha = alpha / k\n",
    "k = 6   # change k to actual number of tests you've run\n",
    "adjusted_alpha = alpha / k\n",
    "print(f\"Bonferroni adjusted alpha for {k} tests: {adjusted_alpha:.6f}\")\n",
    "print(\"If you want FDR (Benjamini-Hochberg), use statsmodels.sandbox or custom code.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "278d9469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaffold report saved to ../reports/Task3_HypothesisTesting_Report.md\n"
     ]
    }
   ],
   "source": [
    "# Cell 11: generate a scaffold report (update manually with p-values & decisions from outputs)\n",
    "report_lines = []\n",
    "report_lines.append(\"# Task 3 - Hypothesis Testing Results\\n\")\n",
    "report_lines.append(\"**Dataset:** data/MachineLearningRating_v3.txt\\n\")\n",
    "report_lines.append(\"**Alpha:** 0.05\\n\\n\")\n",
    "\n",
    "report_lines.append(\"## Tests performed\\n\")\n",
    "report_lines.append(\"- Claim Frequency by Province (Chi-squared)\\n\")\n",
    "report_lines.append(\"- Claim Severity by Province (ANOVA / Kruskal-Wallis)\\n\")\n",
    "report_lines.append(\"- Margin by Province (ANOVA / Kruskal-Wallis)\\n\")\n",
    "report_lines.append(\"- Postal code pairwise comparisons (top 2 by count) — proportions z-test, severity & margin tests\\n\")\n",
    "report_lines.append(\"- Margin across postal codes (ANOVA / Kruskal-Wallis)\\n\")\n",
    "report_lines.append(\"- Gender comparisons: frequency (z-test), severity (t/Mann-Whitney), margin (t/Mann-Whitney)\\n\\n\")\n",
    "\n",
    "report_lines.append(\"## Summary - Fill with decisions from notebook outputs\\n\")\n",
    "report_lines.append(\"- Provinces (frequency): REPLACE_WITH_DECISION (p = REPLACE_WITH_P)\\n\")\n",
    "report_lines.append(\"- Provinces (severity): REPLACE_WITH_DECISION (p = REPLACE_WITH_P)\\n\")\n",
    "report_lines.append(\"- Provinces (margin): REPLACE_WITH_DECISION (p = REPLACE_WITH_P)\\n\")\n",
    "report_lines.append(\"- Postal codes (frequency top2): REPLACE_WITH_DECISION (p = REPLACE_WITH_P)\\n\")\n",
    "report_lines.append(\"- Postal codes (margin top2): REPLACE_WITH_DECISION (p = REPLACE_WITH_P)\\n\")\n",
    "report_lines.append(\"- Postal codes (margin multi-group): REPLACE_WITH_DECISION (p = REPLACE_WITH_P)\\n\")\n",
    "report_lines.append(\"- Gender (frequency): REPLACE_WITH_DECISION (p = REPLACE_WITH_P)\\n\")\n",
    "report_lines.append(\"- Gender (severity): REPLACE_WITH_DECISION (p = REPLACE_WITH_P)\\n\")\n",
    "report_lines.append(\"- Gender (margin): REPLACE_WITH_DECISION (p = REPLACE_WITH_P)\\n\\n\")\n",
    "\n",
    "report_lines.append(\"## Business Recommendations (example templates)\\n\")\n",
    "report_lines.append(\"- If you reject H0 for Province frequency/severity: \\\"We REJECT H0 (p < 0.05). Province X shows higher claim frequency/severity — recommend revising premiums or underwriting criteria in Province X.\\\"\\n\")\n",
    "report_lines.append(\"- If you reject H0 for PostalCode margin: \\\"We REJECT H0 (p < 0.05). Postal code Y shows lower margins — consider investigating local risk factors and adjusting pricing or marketing strategy.\\\"\\n\")\n",
    "report_lines.append(\"- If you find gender differences: \\\"We REJECT H0 (p < 0.05). Differences between genders exist for KPI Z — evaluate potential causes and ensure non-discriminatory underwriting.\\\"\\n\")\n",
    "\n",
    "# Save markdown\n",
    "out_path = \"../reports/Task3_HypothesisTesting_Report.md\"\n",
    "import os\n",
    "os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.writelines([ln+\"\\n\" for ln in report_lines])\n",
    "\n",
    "print(\"Scaffold report saved to\", out_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python AlphaCare (.venv)",
   "language": "python",
   "name": "alphacare_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
